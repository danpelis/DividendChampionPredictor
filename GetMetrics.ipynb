{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GetMetrics Notebook\n",
    "#####  Uses Ticker Symbol lists from GetTickers, we collect dividend values using Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Ticker data from GetTickers.ipynb\n",
    "kept_status = np.load(\"data/numpy/kept_status.npy\")\n",
    "lost_status = np.load(\"data/numpy/lost_status.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['CINF', 'ADM', 'BANF', 'CWT', 'SCL', 'NC', 'SPGI', 'CAT', 'ADP',\n",
       "        'BRO', 'WBA', 'SWK', 'FUL', 'EMR', 'ATO', 'EBTC', 'AFL', 'CHD',\n",
       "        'MDT', 'SYY', 'ECL', 'PPG', 'GRC', 'ROP', 'CSL', 'NJR', 'HRL',\n",
       "        'TRI', 'TROW', 'JNJ', 'SHW', 'PG', 'SBSI', 'TNC', 'PII', 'RNR',\n",
       "        'WEYS', 'WMT', 'NDSN', 'FELE', 'CVX', 'NWN', 'T', 'AROW', 'UHT',\n",
       "        'BDX', 'SJW', 'DCI', 'ABM', 'NEE', 'MO', 'LANC', 'XOM', 'APD',\n",
       "        'WTRG', 'PNR', 'TGT', 'MGEE', 'THFF', 'WST', 'ERIE', 'FLIC',\n",
       "        'FFMR', 'GWW', 'GD', 'O', 'MCD', 'SON', 'SEIC', 'MATW', 'NIDB',\n",
       "        'AWR', 'ED', 'NUE', 'LIN', 'MDU', 'JKHY', 'LECO', 'UVV', 'MSEX',\n",
       "        'UBSI', 'LOW', 'TMP', 'PSBQ', 'CTBI', 'KMB', 'MGRC', 'EFSI', 'BRC',\n",
       "        'LEG', 'PH', 'NNN', 'CFR', 'ATR', 'UGI', 'ITW', 'BEN', 'WABC',\n",
       "        'DOV', 'SYK', 'ENB', 'CTAS', 'BMI', 'PBCT', 'CLX', 'FRT', 'CPKF',\n",
       "        'MKC', 'TDS', 'TR', 'PEP', 'VFC', 'MCY', 'BKH', 'UMBF', 'IBM',\n",
       "        'AOS', 'CBU', 'ESS', 'MMM', 'EXPD', 'CSVI', 'ARTNA', 'CBSH', 'NFG',\n",
       "        'CNI', 'OZK', 'SRCE', 'GPC', 'CL', 'RLI', 'ORI', 'RPM', 'FMCB',\n",
       "        'KO', 'MSA', 'ALB'], dtype='<U5'),\n",
       " array(['BXS', 'BOH', 'LLY', 'TEG', 'TFX', 'WSC', 'IRET', 'CTL', 'HGIC',\n",
       "        'WRE', 'ABT', 'MHP', 'PBI', 'DBD', 'EGN', 'WAG', 'FDO', 'SIAL',\n",
       "        'CB', 'MHFI', 'STR', 'RAVN', 'PNY', 'HCP', 'CLC', 'LLTC', 'VAL',\n",
       "        'BCR', 'WGL', 'PX', 'VVC', 'BMS', 'CTWS', 'WTR', 'TYCB', 'HP',\n",
       "        'MDP', 'UTX', 'ROST', 'SKT', 'UBA', 'RTX', 'EV'], dtype='<U32'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kept_status, lost_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dict with keys set to ticker symbols\n",
    "kept = defaultdict(None)\n",
    "lost = defaultdict(None)\n",
    "\n",
    "for tckr in kept_status:\n",
    "    kept[tckr] = yf.Ticker(tckr)\n",
    "\n",
    "for tckr in lost_status:\n",
    "    lost[tckr] = yf.Ticker(tckr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Ticker Count: 180\n"
     ]
    }
   ],
   "source": [
    "size = len(kept.keys()) + len(lost.keys())\n",
    "print(\"Total Ticker Count:\", size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cleaning up data\n",
    "# Want to fill as many gaps as possible\n",
    "# by ensuring there are 4 dividend values for each year\n",
    "# Some companies may simply not post as frequent, but we wanted\n",
    "# to attempt to maintain a consistent dataset length for each company\n",
    "def fixData(t,status):\n",
    "    # figure out which years can be filled with more samples\n",
    "    years = []\n",
    "    for i in range(len(t.dividends)):\n",
    "        years.append(t.dividends.index[i].year)\n",
    "    year, ct = np.unique(np.array(years), return_counts=True)\n",
    "    fix_years = year[ct<4]\n",
    "    \n",
    "    # Get dividend data for current ticker\n",
    "    df = t.dividends.to_frame().reset_index()\n",
    "\n",
    "    # fill in new values based on whether the company lost or kept status\n",
    "    if fix_years.size > 0:\n",
    "        for yr in fix_years:\n",
    "            dont_fix_years = year[ct>4]\n",
    "            if yr-1 in dont_fix_years or yr+1 in dont_fix_years:\n",
    "                # Adjust expected month counts\n",
    "                # Take into respect instances in which the prev or\n",
    "                # following year had more than 4 dividend updates\n",
    "                if ct[year==yr-1] > 4:\n",
    "                    ct[year==yr-1] -= 1\n",
    "                    ct[year==yr] += 1\n",
    "                elif ct[year==yr+1] > 4:\n",
    "                    ct[year==yr+1] -= 1\n",
    "                    ct[year==yr] += 1\n",
    "                continue\n",
    "            # Collect all the years in which there \n",
    "            # is dividend data available for the current company\n",
    "            years = []\n",
    "            for i in range(len(df.Dividends)):\n",
    "                years.append(df.Date[i].year)\n",
    "            # Get Datetime value to fill in index column for month/year\n",
    "            indx = df[years==yr].index[-1]\n",
    "            for i in range(4-ct[year==yr][0]):\n",
    "                # insert new dividend value with 0 if lost status\n",
    "                # otherwise use the previous value\n",
    "                val = 0 if status in \"lost\" else df.loc[indx].Dividends\n",
    "                df.loc[indx + 0.5] = df.loc[indx].Date,val\n",
    "                df = df.sort_index().reset_index(drop=True)\n",
    "                indx += 1\n",
    "    \n",
    "    # Locate large outliers and replace with copy of previous value\n",
    "    filt = np.convolve(np.array([1,0,-1]), df.values[:,1])\n",
    "    for i in range(len(filt)):\n",
    "        if filt[i] > 0.1 and filt[i+2] < 0:\n",
    "            df.iloc[i,1] = df.iloc[i-1,1] \n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/my/lq0q5bb97h3g3w8mx_7cxjf00000gn/T/ipykernel_19198/1593434647.py:25: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if ct[year==yr-1] > 4:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- BXS: No data found, symbol may be delisted\n",
      "- BXS: No data found, symbol may be delisted\n",
      "- BXS: No data found, symbol may be delisted\n",
      "Skipping BXS, no data available\n",
      "Skipping TEG, no data available\n",
      "Skipping WSC, no data available\n",
      "- IRET: No data found, symbol may be delisted\n",
      "- IRET: No data found, symbol may be delisted\n",
      "- IRET: No data found, symbol may be delisted\n",
      "Skipping IRET, no data available\n",
      "- CTL: No data found, symbol may be delisted\n",
      "- CTL: No data found, symbol may be delisted\n",
      "- CTL: No data found, symbol may be delisted\n",
      "Skipping CTL, no data available\n",
      "- HGIC: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- HGIC: No data found for this date range, symbol may be delisted\n",
      "- HGIC: No data found for this date range, symbol may be delisted\n",
      "Skipping HGIC, no data available\n",
      "Skipping MHP, no data available\n",
      "- WAG: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- WAG: No data found for this date range, symbol may be delisted\n",
      "- WAG: No data found for this date range, symbol may be delisted\n",
      "Skipping WAG, no data available\n",
      "- FDO: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- FDO: No data found for this date range, symbol may be delisted\n",
      "- FDO: No data found for this date range, symbol may be delisted\n",
      "Skipping FDO, no data available\n",
      "- SIAL: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- SIAL: No data found for this date range, symbol may be delisted\n",
      "- SIAL: No data found for this date range, symbol may be delisted\n",
      "Skipping SIAL, no data available\n",
      "- MHFI: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- MHFI: No data found for this date range, symbol may be delisted\n",
      "- MHFI: No data found for this date range, symbol may be delisted\n",
      "Skipping MHFI, no data available\n",
      "Skipping STR, no data available\n",
      "- RAVN: No data found, symbol may be delisted\n",
      "- RAVN: No data found, symbol may be delisted\n",
      "- RAVN: No data found, symbol may be delisted\n",
      "Skipping RAVN, no data available\n",
      "- PNY: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- PNY: No data found for this date range, symbol may be delisted\n",
      "- PNY: No data found for this date range, symbol may be delisted\n",
      "Skipping PNY, no data available\n",
      "- HCP: Data doesn't exist for startDate = -2208970800, endDate = 1609390800\n",
      "Skipping HCP, no data available\n",
      "Skipping CLC, no data available\n",
      "- LLTC: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- LLTC: No data found for this date range, symbol may be delisted\n",
      "- LLTC: No data found for this date range, symbol may be delisted\n",
      "Skipping LLTC, no data available\n",
      "- VAL: Data doesn't exist for startDate = -2208970800, endDate = 1609390800\n",
      "Skipping VAL, no data available\n",
      "- BCR: 1d data not available for startTime=-2208970800 and endTime=1609390800. Only 100 years worth of day granularity data are allowed to be fetched per request.\n",
      "- BCR: No data found for this date range, symbol may be delisted\n",
      "- BCR: No data found for this date range, symbol may be delisted\n",
      "Skipping BCR, no data available\n",
      "- PX: Data doesn't exist for startDate = -2208970800, endDate = 1609390800\n",
      "Skipping PX, no data available\n",
      "Skipping VVC, no data available\n",
      "- CTWS: No data found, symbol may be delisted\n",
      "- CTWS: No data found, symbol may be delisted\n",
      "- CTWS: No data found, symbol may be delisted\n",
      "Skipping CTWS, no data available\n",
      "- WTR: No data found, symbol may be delisted\n",
      "- WTR: No data found, symbol may be delisted\n",
      "- WTR: No data found, symbol may be delisted\n",
      "Skipping WTR, no data available\n",
      "- MDP: No data found for this date range, symbol may be delisted\n",
      "Skipping MDP, no data available\n",
      "- UTX: No data found, symbol may be delisted\n",
      "- UTX: No data found, symbol may be delisted\n",
      "- UTX: No data found, symbol may be delisted\n",
      "Skipping UTX, no data available\n",
      "- EV: No data found, symbol may be delisted\n",
      "- EV: No data found, symbol may be delisted\n",
      "- EV: No data found, symbol may be delisted\n",
      "Skipping EV, no data available\n"
     ]
    }
   ],
   "source": [
    "# Loop through kept and lost status dictionaries\n",
    "# Collect dividend data and fix datasets that don't\n",
    "# contain 4 dividend updates per year\n",
    "# Update kept/lost lists based on data that is able to be collected\n",
    "# save collected samples as csvs that can be used in ML/DL algorithms\n",
    "for t in kept_status:\n",
    "    try:\n",
    "        tick = kept[t]\n",
    "        tick.history(start='1900-1-1', end='2020-12-31')\n",
    "        div = fixData(tick,\"kept\")\n",
    "        div = pd.Series(div.Dividends.values, index=div.Date)\n",
    "        if not div.empty:\n",
    "            div.to_csv(f'data/series/good/{t}_dividends_fixed.csv')\n",
    "    except Exception as e:\n",
    "        print(f'Skipping {t}, no data available')\n",
    "        \n",
    "for t in lost_status:\n",
    "    try:\n",
    "        tick = lost[t]\n",
    "        tick.history(start='1900-1-1', end='2020-12-31')\n",
    "        div = fixData(tick,\"lost\")\n",
    "        div = pd.Series(div.Dividends.values, index=div.Date)\n",
    "        if not div.empty:\n",
    "            div.to_csv(f'data/series/good/{t}_dividends_fixed.csv')\n",
    "    except Exception as e:\n",
    "        print(f'Skipping {t}, no data available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At this stage all necessary data has be collected, fixed, and stored as csv's. These will be the datasets used as the input to our algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eeb0b1f2d66c270eb7919ffa3ebf5524e197563bda0b15333d41dd481ffcf213"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
