{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Forecasting\n",
    "The code below runs the ARIMA model for 8 different companies, 4 that maintained Dividend Champion status and 4 that lost status. The test forecasts are saved to a `.npy` file so they could be combined with the forecasts from the other models to be compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import lag_plot\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')    # ignore warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Dataframe into train and test set\n",
    "def split(dataframe, border, col):\n",
    "    return dataframe.loc[:border,col], dataframe.loc[border:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABM', 'ABT', 'ADM', 'ADP', 'AFL', 'ALB', 'AOS', 'APD', 'AROW', 'ARTNA', 'ATO', 'ATR', 'AWR', 'BANF', 'BDX', 'BEN', 'BKH', 'BMI', 'BMS', 'BOH', 'BRC', 'BRO', 'CAT', 'CBSH', 'CBU', 'CB', 'CFR', 'CHD', 'CINF', 'CLX', 'CL', 'CNI', 'CPKF', 'CSL', 'CSVI', 'CTAS', 'CTBI', 'CVX', 'CWT', 'DBD', 'DCI', 'DOV', 'EBTC', 'ECL', 'ED', 'EFSI', 'EGN', 'EMR', 'ENB', 'ERIE', 'ESS', 'EXPD', 'FELE', 'FFMR', 'FLIC', 'FMCB', 'FRT', 'FUL', 'GD', 'GPC', 'GRC', 'GWW', 'HP', 'HRL', 'IBM', 'ITW', 'JKHY', 'JNJ', 'KMB', 'KO', 'LANC', 'LECO', 'LEG', 'LIN', 'LLY', 'LOW', 'MATW', 'MCD', 'MCY', 'MDT', 'MDU', 'MGEE', 'MGRC', 'MKC', 'MMM', 'MO', 'MSA', 'MSEX', 'NC', 'NDSN', 'NEE', 'NFG', 'NIDB', 'NJR', 'NNN', 'NUE', 'NWN', 'ORI', 'OZK', 'O', 'PBCT', 'PBI', 'PEP', 'PG', 'PH', 'PII', 'PNR', 'PPG', 'PSBQ', 'RLI', 'RNR', 'ROP', 'ROST', 'RPM', 'RTX', 'SBSI', 'SCL', 'SEIC', 'SHW', 'SJW', 'SKT', 'SON', 'SPGI', 'SRCE', 'SWK', 'SYK', 'SYY', 'TDS', 'TFX', 'TGT', 'THFF', 'TMP', 'TNC', 'TRI', 'TROW', 'TR', 'TYCB', 'T', 'UBA', 'UBSI', 'UGI', 'UHT', 'UMBF', 'UVV', 'VFC', 'WABC', 'WBA', 'WEYS', 'WGL', 'WMT', 'WRE', 'WST', 'WTRG', 'XOM']\n"
     ]
    }
   ],
   "source": [
    "# Collect list of all companies we have data for\n",
    "\n",
    "# Get list of file names\n",
    "fileList = os.listdir(\"../data/series/good\")\n",
    "\n",
    "# Loop through file names and collect ticker symbols\n",
    "companyList = []\n",
    "for file in fileList:\n",
    "    companyName = file.split(\"_\")[0]\n",
    "    if companyName not in [\".DS\",\".ipynb\"]:\n",
    "        companyList.append(companyName)\n",
    "print(companyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add to ignore list if no data is available\n",
    "# Yahoo Finance will occasionally not through error\n",
    "# for some companies during GetMetrics, which end up creating blank\n",
    "# csvs that we can simply ignore here\n",
    "ignoreList = [\"FFMR\",\"FMCB\"]\n",
    "stockList = list(set(companyList).difference(ignoreList))\n",
    "\n",
    "# Load and store data in initial Dataframe\n",
    "df_ = {}\n",
    "for i in stockList:\n",
    "    df_[i] = pd.read_csv(\"../data/series/good/\" + i + \"_dividends_fixed.csv\", index_col=\"Date\", parse_dates=[\"Date\"])\n",
    "\n",
    "# Create new Dataframe that contains data for each company\n",
    "# split at specified year\n",
    "df_new = {}\n",
    "for i in stockList:\n",
    "    df_new[i] = {}\n",
    "    df_new[i][\"Train\"], df_new[i][\"Test\"] = split(df_[i], \"2006\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARIMA\n",
    "def create_arima_model(train_data, test_data):\n",
    "    training_data = train_data.values   \n",
    "    test_data = test_data.values\n",
    "    history = [x for x in training_data]    # make list of training data\n",
    "    model_predictions = []\n",
    "\n",
    "    for time_point in range(len(test_data)):\n",
    "        model = ARIMA(history, order=(1, 1, 1))\n",
    "        model_fit = model.fit()    # fit model\n",
    "        output = model_fit.forecast()    # get out-of-sample forecasts (predictions)\n",
    "        yhat = output[0]    # get value from array\n",
    "        model_predictions.append(yhat)    # list of model predictions\n",
    "        true_test_value = test_data[time_point]    # get true value\n",
    "        history.append(true_test_value)    # append to history (training data)\n",
    "\n",
    "    MSE_error = mean_squared_error(test_data, model_predictions)\n",
    "    print(f'{company} - Testing Mean Squared Error - {MSE_error:.5f}')\n",
    "    \n",
    "    return model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_list = ['MGEE', 'TGT', 'BEN', 'CBSH']\n",
    "lost_list = ['PBI', 'ABT', 'WRE', 'HP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGEE - Testing Mean Squared Error - 0.00003\n",
      "Forecast data saved for - MGEE\n",
      "TGT - Testing Mean Squared Error - 0.00053\n",
      "Forecast data saved for - TGT\n",
      "BEN - Testing Mean Squared Error - 0.00009\n",
      "Forecast data saved for - BEN\n",
      "CBSH - Testing Mean Squared Error - 0.00003\n",
      "Forecast data saved for - CBSH\n"
     ]
    }
   ],
   "source": [
    "# Kept status\n",
    "# Create models for all kept status companies\n",
    "# and get forecasts from test set\n",
    "for company in kept_list:\n",
    "    dividends_train = df_new[company]['Train']\n",
    "    dividends_test = df_new[company]['Test']\n",
    "    \n",
    "    model_predictions = create_arima_model(dividends_train, dividends_test)\n",
    "    model_predictions = np.asarray(model_predictions)\n",
    "    np.save(file = '../data/numpy/' + company + '_pred_arima.npy', arr = model_predictions)\n",
    "    print(f'Forecast data saved for - {company}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PBI - Testing Mean Squared Error - 0.00091\n",
      "Forecast data saved for - PBI\n",
      "ABT - Testing Mean Squared Error - 0.00039\n",
      "Forecast data saved for - ABT\n",
      "WRE - Testing Mean Squared Error - 0.00033\n",
      "Forecast data saved for - WRE\n",
      "HP - Testing Mean Squared Error - 0.00641\n",
      "Forecast data saved for - HP\n"
     ]
    }
   ],
   "source": [
    "# Lost status\n",
    "# Create models for all kept status companies\n",
    "# and get forecasts from test set\n",
    "for company in lost_list:\n",
    "    dividends_train = df_new[company]['Train']\n",
    "    dividends_test = df_new[company]['Test']\n",
    "    \n",
    "    model_predictions = create_arima_model(dividends_train, dividends_test)\n",
    "    model_predictions = np.asarray(model_predictions)\n",
    "    np.save(file = '../data/numpy/' + company + '_pred_arima.npy', arr = model_predictions)\n",
    "    print(f'Forecast data saved for - {company}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
